{"cells":[{"metadata":{},"cell_type":"markdown","source":"**[Deep Learning Home Page](https://www.kaggle.com/learn/deep-learning)**\n\n---\n"},{"metadata":{},"cell_type":"markdown","source":"# Intro\nThe TV show *Silicon Valley* had an app called \"See Food\" that promised to identify food. \n\nIn this notebook, you will write code using and comparing pre-trained models to choose one as an engine for the See Food app.\n\nYou won't go too deep into Keras or TensorFlow details in this particular exercise.  Don't worry. You'll go deeper into model development soon.  For now, you'll make sure you know how to use pre-trained models.\n\n# Set-Up"},{"metadata":{},"cell_type":"markdown","source":"We will run a few steps of environmental set-up before writing your own code. **You don't need to understand the details of this set-up code.** You can just run each code cell until you get to the exercises.\n\n### 1) Create Image Paths\nThis workspace includes image files you will use to test your models. Run the cell below to store a few filepaths to these images in a variable `img_paths`."},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfrom os.path import join\n\n\nhot_dog_image_dir = '../input/hot-dog-not-hot-dog/seefood/train/hot_dog'\n\nhot_dog_paths = [join(hot_dog_image_dir,filename) for filename in \n                            ['1000288.jpg',\n                             '127117.jpg']]\n\nnot_hot_dog_image_dir = '../input/hot-dog-not-hot-dog/seefood/train/not_hot_dog'\nnot_hot_dog_paths = [join(not_hot_dog_image_dir, filename) for filename in\n                            ['823536.jpg',\n                             '99890.jpg']]\n\nimg_paths = hot_dog_paths + not_hot_dog_paths","execution_count":1,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2) Run an Example Model\nHere is the code you saw in the tutorial. It loads data, loads a pre-trained model, and makes predictions. Run this cell too."},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import Image, display\nfrom learntools.deep_learning.decode_predictions import decode_predictions\nimport numpy as np\nfrom tensorflow.keras.applications.resnet50 import preprocess_input\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\n\n\nimage_size = 224\n\ndef read_and_prep_images(img_paths, img_height=image_size, img_width=image_size):\n    imgs = [load_img(img_path, target_size=(img_height, img_width)) for img_path in img_paths]\n    img_array = np.array([img_to_array(img) for img in imgs])\n    output = preprocess_input(img_array)\n    return(output)\n\n\nmy_model = ResNet50(weights='../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels.h5')\ntest_data = read_and_prep_images(img_paths)\npreds = my_model.predict(test_data)\n\nmost_likely_labels = decode_predictions(preds, top=3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3) Visualize Predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, img_path in enumerate(img_paths):\n    display(Image(img_path))\n    print(most_likely_labels[i])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4) Set Up Code Checking\nAs a last step before writing your own code, run the following cell to enable feedback on your code."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set up code checking\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.deep_learning.exercise_3 import *\nprint(\"Setup Complete\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exercises\n\nYou will write a couple useful functions in the next exercises. Then you will put these functions together to compare the effectiveness of various pretrained models for your hot-dog detection program.\n\n### Exercise 1\n\nWe want to distinguish whether an image is a hot dog or not. But our models classify pictures into 1000 different categories. Write a function that takes the models predictions (in the same format as `preds` from the set-up code) and returns a list of `True` and `False` values.\n\nSome tips:\n- Work iteratively. Figure out one line at a time outsie the function, and print that line's output to make sure it's right. Once you have all the code you need, move it into the function `is_hot_dog`. If you get an error, check that you have copied the right code and haven't left anything out.\n- The raw data we loaded in `img_paths` had two images of hot dogs, followed by two images of other foods. So, if you run your function on `preds`, which represents the output of the model on these images, your function should return `[True, True, False, False]`.\n- You will want to use the `decode_predictions` function that was also used in the code provided above. We provided a line with this in the code cell to get you started.\n\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Experiment with code outside the function, then move it into the function once you think it is right\n\n# the following lines are given as a hint to get you started\ndecoded = decode_predictions(preds, top=1)\nprint(decoded)\n\ndef is_hot_dog(preds):\n    '''\n    inputs:\n    preds_array:  array of predictions from pre-trained model\n\n    outputs:\n    is_hot_dog_list: a list indicating which predictions show hotdog as the most likely label\n    '''\n    decoded = decode_predictions(preds, top=1)\n\n    # pull out predicted label, which is in d[0][1] due to how decode_predictions structures results\n    labels = [d[0][1] for d in decoded]\n    out = [l == 'hotdog' for l in labels]\n    return out\n    \n# Check your answer\nq_1.check()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If you'd like to see a hint or the solution, uncomment the appropriate line below.\n\n**If you did not get a working solution, copy the solution code into your code cell above and run it. You will need this function for the next step.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# q_1.hint()\n# q_1.solution()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Exercise 2: Evaluate Model Accuracy\n\nYou have a model (called `my_model`). Is it good enough to build your app around? \n\nFind out by writing a function that calculates a model's accuracy (fraction correct). You will try an alternative model in the next step. So we will put this logic in a reusable function that takes data and the model as arguments, and returns the accuracy.\n\nTips:\n\n - Use the `is_hot_dog` function from above to help write your function\n - To save you some scrolling, here is the code from above where we used a TensorFlow model to make predictions:\n\n```\nmy_model = ResNet50(weights='../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels.h5')\ntest_data = read_and_prep_images(img_paths)\npreds = my_model.predict(test_data)\n```"},{"metadata":{"trusted":true},"cell_type":"code","source":"def calc_accuracy(model, paths_to_hotdog_images, paths_to_other_images):\n    # Use counts for denominator of accuracy calculation\n    num_hot_dog_images = len(paths_to_hotdog_images)\n    num_other_images = len(paths_to_other_images)\n    hotdog_image_data = read_and_prep_images(paths_to_hotdog_images)\n    preds_for_hotdogs = model.predict(hotdog_image_data)\n    # Summing list of binary variables gives a count of True values\n    num_correct_hotdog_preds = sum(is_hot_dog(preds_for_hotdogs))\n    other_image_data = read_and_prep_images(paths_to_other_images)\n    preds_other_images = model.predict(other_image_data)\n    # Number correct is the number judged not to be hot dogs\n    num_correct_other_preds = num_other_images - sum(is_hot_dog(preds_other_images))\n    total_correct = num_correct_hotdog_preds + num_correct_other_preds\n    total_preds = num_hot_dog_images + num_other_images\n    return total_correct / total_preds\n\n# Code to call calc_accuracy.  my_model, hot_dog_paths and not_hot_dog_paths were created in the setup code\nmy_model_accuracy = calc_accuracy(my_model, hot_dog_paths, not_hot_dog_paths)\nprint(\"Fraction correct in small test set: {}\".format(my_model_accuracy))\n\n# Check your answer\nq_2.check()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If you'd like a hint or the solution, uncomment the appropriate line below"},{"metadata":{"trusted":true},"cell_type":"code","source":"# q_2.hint()\n# q_2.solution()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Exercise 3:\nThere are other models besides the ResNet model (which we have loaded). For example, an earlier winner of the ImageNet competition is the VGG16 model.  Don't worry about the differences between these models yet. We'll come back to that later. For now, just focus on the mechanics of applying these models to a problem.\n\nThe code used to load a pretrained ResNet50 model was\n\n```\nmy_model = ResNet50(weights='../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels.h5')\n```\n\nThe weights for the model are stored at `../input/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5`.\n\nIn the cell below, create a VGG16 model with the preloaded weights. Then use your `calc_accuracy` function to determine what fraction of images the VGG16 model correctly classifies.  Is it better or worse than the pretrained ResNet model?"},{"metadata":{"trusted":true},"cell_type":"code","source":"# import the model\nfrom tensorflow.keras.applications import VGG16\n\n\nvgg16_model = VGG16(weights='../input/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5')\n# calculate accuracy on small dataset as a test\nvgg16_accuracy = calc_accuracy(vgg16_model, hot_dog_paths, not_hot_dog_paths)\n\nprint(\"Fraction correct in small dataset: {}\".format(vgg16_accuracy))\n\n# Check your answer\nq_3.check()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Uncomment the appropriate line below if you'd like a hint or the solution"},{"metadata":{"trusted":true},"cell_type":"code","source":"# q_3.hint()\n# q_3.solution()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If this model is used for an app that runs on a phone, what factors besides accuracy might you care about? After you've thought about it, keep going below."},{"metadata":{},"cell_type":"markdown","source":"# Keep Going\nYou are ready for **[Transfer Learning](https://www.kaggle.com/dansbecker/transfer-learning/)**, which will allow you to apply the same level of power for your custom purposes.\n"},{"metadata":{},"cell_type":"markdown","source":"---\n**[Deep Learning Home Page](https://www.kaggle.com/learn/deep-learning)**\n\n\n\n\n\n*Have questions or comments? Visit the [Learn Discussion forum](https://www.kaggle.com/learn-forum) to chat with other Learners.*"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":2}